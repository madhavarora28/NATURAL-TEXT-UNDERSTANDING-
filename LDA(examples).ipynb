{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f40a7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ai' 'learning' 'machine']\n",
      "[[0 1 1]\n",
      " [0 2 1]\n",
      " [1 0 0]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "documents = [\"Machine learning is amazing!\",\n",
    "            \"Deep learning is a subset of machine learning.\",\n",
    "            \"Natural language processing is a part of AI.\",\n",
    "            \"AI is transforming the world.\"]\n",
    "\n",
    "cv = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "dtm = cv.fit_transform(documents) # convert text to document-term matrix\n",
    "\n",
    "print(cv.get_feature_names_out()) #display remaining words\n",
    "print(dtm.toarray())  # show the word counts in documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d0ff59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "natural\n",
      "machine\n",
      "subset\n",
      "ai\n",
      "learning\n",
      "language\n",
      "language\n",
      "learning\n",
      "ai\n",
      "language\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#sample text corpus\n",
    "documents = [\"Machine learning is amazing!\",\n",
    "            \"Deep learning is a subset of machine learning.\",\n",
    "            \"Natural language processing is a part of AI.\"]\n",
    "\n",
    "#convert text into a document-term matrix=DTM\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "dtm = cv.fit_transform(documents)\n",
    "#get feature names\n",
    "feature_names = cv.get_feature_names_out() #updated method\n",
    "\n",
    "#generate 10 random words from the vocabulary\n",
    "for i in range(10):\n",
    "    random_word_id = random.randint(0, len(feature_names) -1) #use the actual vocabulary size\n",
    "    print(feature_names[random_word_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a72509f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 is mostly about Topic 1\n",
      "Document 2 is mostly about Topic 0\n",
      "Document 3 is mostly about Topic 1\n",
      "Document 4 is mostly about Topic 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#sample corpus\n",
    "documents = [\"I love Machine learning and data science!\",\n",
    "            \"Deep learning is a subset of machine learning.\",\n",
    "            \"I enjoy playing football and watching sports.\",\n",
    "             \"Sports analytics is an interesting field\"]\n",
    "\n",
    "#convert text to document-term matrix\n",
    "vectorizer= CountVectorizer(stop_words='english')\n",
    "dtm = vectorizer.fit_transform(documents)\n",
    "\n",
    "#Train the LDA model\n",
    "lda = LatentDirichletAllocation(n_components=2, random_state=42)\n",
    "lda.fit(dtm)\n",
    "\n",
    "#get topic distribution for each document\n",
    "topic_results= lda.transform(dtm) #shape: (num_docs, num_topics)\n",
    "\n",
    "#identify the dominant topic for each document\n",
    "dominant_topics = topic_results.argmax(axis=1)\n",
    "\n",
    "#print results\n",
    "for i, topic in enumerate(dominant_topics):\n",
    "    print(f\"Document {i+1} is mostly about Topic {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd6b631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
